{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consumer_key='jM1PmETmzFK9LATdshxiTUhpo'\n",
    "Consumer_secret='Jq3wel0dfiyG3Wucnz5q5uLeWYEu5o23UwTB31L77zsuN8DX4V'\n",
    "Access_key='1286901432424124416-R6DlbDDK2hgdYyiwUuzGhZ6KBKribp'\n",
    "Access_secret='ZrYBsM4KH5xY684IBYTpz9Vqy9ELFAZDgpLjAV6dQ1XpX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltweets = []\t\n",
    "def get_all_tweets(screen_name):\n",
    "    auth = tweepy.OAuthHandler(Consumer_key,Consumer_secret)\n",
    "    auth.set_access_token(Access_key,Access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    oldest = alltweets[-1].id - 1\n",
    "    while len(new_tweets)>0:\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest) #save most recent tweets\n",
    "        alltweets.extend(new_tweets) #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "        \n",
    "    outtweets = [[tweet.created_at,tweet.entities[\"hashtags\"],tweet.entities[\"user_mentions\"],tweet.favorite_count,\n",
    "                  tweet.geo,tweet.id_str,tweet.lang,tweet.place,tweet.retweet_count,tweet.retweeted,tweet.source,tweet.text,\n",
    "                  tweet._json[\"user\"][\"location\"],tweet._json[\"user\"][\"name\"],tweet._json[\"user\"][\"time_zone\"],\n",
    "                  tweet._json[\"user\"][\"utc_offset\"]] for tweet in alltweets]\n",
    "    \n",
    "    \n",
    "    tweets_df = pd.DataFrame(columns = [\"time\",\"hashtags\",\"user_mentions\",\"favorite_count\",\n",
    "                                    \"geo\",\"id_str\",\"lang\",\"place\",\"retweet_count\",\"retweeted\",\"source\",\n",
    "                                    \"text\",\"location\",\"name\",\"time_zone\",\"utc_offset\"])\n",
    "    tweets_df[\"time\"]  = pd.Series([str(i[0]) for i in outtweets])\n",
    "    tweets_df[\"hashtags\"] = pd.Series([str(i[1]) for i in outtweets])\n",
    "    tweets_df[\"user_mentions\"] = pd.Series([str(i[2]) for i in outtweets])\n",
    "    tweets_df[\"favorite_count\"] = pd.Series([str(i[3]) for i in outtweets])\n",
    "    tweets_df[\"geo\"] = pd.Series([str(i[4]) for i in outtweets])\n",
    "    tweets_df[\"id_str\"] = pd.Series([str(i[5]) for i in outtweets])\n",
    "    tweets_df[\"lang\"] = pd.Series([str(i[6]) for i in outtweets])\n",
    "    tweets_df[\"place\"] = pd.Series([str(i[7]) for i in outtweets])\n",
    "    tweets_df[\"retweet_count\"] = pd.Series([str(i[8]) for i in outtweets])\n",
    "    tweets_df[\"retweeted\"] = pd.Series([str(i[9]) for i in outtweets])\n",
    "    tweets_df[\"source\"] = pd.Series([str(i[10]) for i in outtweets])\n",
    "    tweets_df[\"text\"] = pd.Series([str(i[11]) for i in outtweets])\n",
    "    tweets_df[\"location\"] = pd.Series([str(i[12]) for i in outtweets])\n",
    "    tweets_df[\"name\"] = pd.Series([str(i[13]) for i in outtweets])\n",
    "    tweets_df[\"time_zone\"] = pd.Series([str(i[14]) for i in outtweets])\n",
    "    tweets_df[\"utc_offset\"] = pd.Series([str(i[15]) for i in outtweets])\n",
    "    tweets_df.to_csv(screen_name+\"_tweets.csv\")\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2162 tweets downloaded so far\n",
      "...2162 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "tweet = get_all_tweets(\"imVkohli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\nthambat\\\\Downloads\\\\DS\\\\imVkohli_tweets.csv',usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An electrifying catch âš¡ âš¡ âš¡, this shoe is dial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal endangerment is a pressing issue and I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸŒ… https://t.co/xwR5YJ7Xty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Many happy returns of the day @coach_rsridhar....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @GoogleIndia: The Captain's excited to meet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  An electrifying catch âš¡ âš¡ âš¡, this shoe is dial...\n",
       "1  Animal endangerment is a pressing issue and I ...\n",
       "2                          ðŸŒ… https://t.co/xwR5YJ7Xty\n",
       "3  Many happy returns of the day @coach_rsridhar....\n",
       "4  RT @GoogleIndia: The Captain's excited to meet..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   # Importing requests to extract content from a url\n",
    "from bs4 import BeautifulSoup as bs # Beautifulsoup is for web scrapping...used to scrap specific content \n",
    "import re # regular expressions \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
